{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignmnet 3 (100 + 5 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Name:** Dev Bhanushali<br>\n",
    "**Email:** deb3962@thi.de<br>\n",
    "**Group:** A <br>\n",
    "**Hours spend *(optional)* : 10-15 Hrs** <br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 1: Transformer model *(100 points)*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As a Machine Learning engineer at a tech company, you were given a task to develop a machine translation system that translates **English (source) to German (Target)**. You can use existing libraries but the training needs to be done from scratch (usage of pretrained weights is not allowed). You have the freedom to select any dataset for training the model. Use a small subset of data as a validation dataset and report the BLEU score on the validation set. Also, provide a short description of your transformer model architecture, hyperparameters, and training (also provide the training loss curve)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Submission </h3>\n",
    "\n",
    "The test set **(test.txt)** will be released one week before the deadline. You should submit the output of your model on the test set separately. Name the output file as **\"first name_last_name_test_result.txt\"**. Each line of the submission file should contain only the translated text of the corresponding sentence from 'test.txt'.\n",
    "\n",
    "The 'first name_last_name_test_result.txt' file will be evaluated by your instructor and the student who could get the best BLEU score will get 5 additional points. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Dataset**\n",
    "\n",
    "Here are some of the parallel datasets (see Datasets and Resources file):\n",
    "* Europarl Parallel corpus - https://www.statmt.org/europarl/v7/de-en.tgz\n",
    "* News Commentary - https://www.statmt.org/wmt14/training-parallel-nc-v9.tgz (use DE-EN parallel data)\n",
    "* Common Crawl corpus - https://www.statmt.org/wmt13/training-parallel-commoncrawl.tgz (use DE-EN parallel data)\n",
    "\n",
    "You can also use other datasets of your choice. In the above datasets, **'.en'** file has the text in English, and **'.de'** file contains their corresponding German translations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notes:\n",
    "\n",
    "1) You can also consider using a small subset of the dataset if the training dataset is large\n",
    "2) Sometimes you can also get out of memory errors while training, so choose the hyperparameters carefully.\n",
    "3) Your training will be much faster if you use a GPU. If you are using a CPU, it may take several hours or even days. (you can also use Google Colab GPUs for training. link: https://colab.research.google.com/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\devbh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torchtext\\data\\__init__.py:4: UserWarning: \n",
      "/!\\ IMPORTANT WARNING ABOUT TORCHTEXT STATUS /!\\ \n",
      "Torchtext is deprecated and the last released version will be 0.18 (this one). You can silence this warning by calling the following at the beginnign of your scripts: `import torchtext; torchtext.disable_torchtext_deprecation_warning()`\n",
      "  warnings.warn(torchtext._TORCHTEXT_DEPRECATION_MSG)\n",
      "c:\\Users\\devbh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torchtext\\vocab\\__init__.py:4: UserWarning: \n",
      "/!\\ IMPORTANT WARNING ABOUT TORCHTEXT STATUS /!\\ \n",
      "Torchtext is deprecated and the last released version will be 0.18 (this one). You can silence this warning by calling the following at the beginnign of your scripts: `import torchtext; torchtext.disable_torchtext_deprecation_warning()`\n",
      "  warnings.warn(torchtext._TORCHTEXT_DEPRECATION_MSG)\n",
      "c:\\Users\\devbh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torchtext\\utils.py:4: UserWarning: \n",
      "/!\\ IMPORTANT WARNING ABOUT TORCHTEXT STATUS /!\\ \n",
      "Torchtext is deprecated and the last released version will be 0.18 (this one). You can silence this warning by calling the following at the beginnign of your scripts: `import torchtext; torchtext.disable_torchtext_deprecation_warning()`\n",
      "  warnings.warn(torchtext._TORCHTEXT_DEPRECATION_MSG)\n",
      "c:\\Users\\devbh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torchtext\\datasets\\__init__.py:4: UserWarning: \n",
      "/!\\ IMPORTANT WARNING ABOUT TORCHTEXT STATUS /!\\ \n",
      "Torchtext is deprecated and the last released version will be 0.18 (this one). You can silence this warning by calling the following at the beginnign of your scripts: `import torchtext; torchtext.disable_torchtext_deprecation_warning()`\n",
      "  warnings.warn(torchtext._TORCHTEXT_DEPRECATION_MSG)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "torch.utils.data.datapipes.utils.common.DILL_AVAILABLE = torch.utils._import_utils.dill_available()\n",
    "\n",
    "from typing import Iterable, List\n",
    "from torchtext.data.utils import get_tokenizer\n",
    "from torchtext.vocab import build_vocab_from_iterator\n",
    "from torchtext.datasets import multi30k, Multi30k"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "gpu check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "NVIDIA GeForce RTX 4090 Laptop GPU\n"
     ]
    }
   ],
   "source": [
    "print(torch.cuda.device_count())\n",
    "print(torch.cuda.get_device_name(0))\n",
    "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Util functions for Data Loading"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "importing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "multi30k.URL[\"train\"] = \"https://raw.githubusercontent.com/neychev/small_DL_repo/master/datasets/Multi30k/training.tar.gz\"\n",
    "multi30k.URL[\"valid\"] = \"https://raw.githubusercontent.com/neychev/small_DL_repo/master/datasets/Multi30k/validation.tar.gz\"\n",
    "TGT_LANGUAGE = 'de'\n",
    "SRC_LANGUAGE = 'en'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "token_transform = {}\n",
    "vocab_transform = {}\n",
    "\n",
    "# load tokenizers\n",
    "token_transform[SRC_LANGUAGE] = get_tokenizer('spacy', language='de_core_news_sm')\n",
    "token_transform[TGT_LANGUAGE] = get_tokenizer('spacy', language='en_core_web_sm')\n",
    "\n",
    "# set special symbol indices\n",
    "UNK_IDX, PAD_IDX, BOS_IDX, EOS_IDX = 0, 1, 2, 3\n",
    "special_symbols = ['<unk>', '<pad>', '<bos>', '<eos>']\n",
    "\n",
    "def yield_tokens(data_iter: Iterable, language: str):\n",
    "    language_index = {SRC_LANGUAGE: 0, TGT_LANGUAGE: 1}\n",
    "    for data_sample in data_iter:\n",
    "        yield token_transform[language](data_sample[language_index[language]])\n",
    "\n",
    "for ln in [SRC_LANGUAGE, TGT_LANGUAGE]:\n",
    "    train_iter = Multi30k(split='train', language_pair=(SRC_LANGUAGE, TGT_LANGUAGE))\n",
    "    vocab_transform[ln] = build_vocab_from_iterator(yield_tokens(train_iter, ln), min_freq=1, specials=special_symbols, special_first=True)\n",
    "\n",
    "for ln in [SRC_LANGUAGE, TGT_LANGUAGE]:\n",
    "  vocab_transform[ln].set_default_index(UNK_IDX)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transformer Architecture"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transformer Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import Tensor\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import Transformer\n",
    "import math\n",
    "\n",
    "# Positional encoding\n",
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self,\n",
    "                 emb_size: int,\n",
    "                 dropout: float,\n",
    "                 maxlen: int = 5000):\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "        den = torch.exp(- torch.arange(0, emb_size, 2)* math.log(10000) / emb_size)\n",
    "        pos = torch.arange(0, maxlen).reshape(maxlen, 1)\n",
    "        pos_embedding = torch.zeros((maxlen, emb_size))\n",
    "        pos_embedding[:, 0::2] = torch.sin(pos * den)\n",
    "        pos_embedding[:, 1::2] = torch.cos(pos * den)\n",
    "        pos_embedding = pos_embedding.unsqueeze(-2)\n",
    "\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.register_buffer('pos_embedding', pos_embedding)\n",
    "\n",
    "    def forward(self, token_embedding: Tensor):\n",
    "        return self.dropout(token_embedding + self.pos_embedding[:token_embedding.size(0), :])\n",
    "\n",
    "# encode tensor input indices to tensor of token embedding\n",
    "class TokenEmbedding(nn.Module):\n",
    "    def __init__(self, vocab_size: int, emb_size):\n",
    "        super(TokenEmbedding, self).__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, emb_size)\n",
    "        self.emb_size = emb_size\n",
    "\n",
    "    def forward(self, tokens: Tensor):\n",
    "        return self.embedding(tokens.long()) * math.sqrt(self.emb_size)\n",
    "\n",
    "# Transformer architecture\n",
    "class Seq2SeqTransformer(nn.Module):\n",
    "    def __init__(self,\n",
    "                 num_encoder_layers: int,\n",
    "                 num_decoder_layers: int,\n",
    "                 emb_size: int,\n",
    "                 nhead: int,\n",
    "                 src_vocab_size: int,\n",
    "                 tgt_vocab_size: int,\n",
    "                 dim_feedforward: int = 512,\n",
    "                 dropout: float = 0.1):\n",
    "        super(Seq2SeqTransformer, self).__init__()\n",
    "        self.transformer = Transformer(d_model=emb_size,\n",
    "                                       nhead=nhead,\n",
    "                                       num_encoder_layers=num_encoder_layers,\n",
    "                                       num_decoder_layers=num_decoder_layers,\n",
    "                                       dim_feedforward=dim_feedforward,\n",
    "                                       dropout=dropout)\n",
    "        self.generator = nn.Linear(emb_size, tgt_vocab_size)\n",
    "        self.src_tok_emb = TokenEmbedding(src_vocab_size, emb_size)\n",
    "        self.tgt_tok_emb = TokenEmbedding(tgt_vocab_size, emb_size)\n",
    "        self.positional_encoding = PositionalEncoding(\n",
    "            emb_size, dropout=dropout)\n",
    "\n",
    "    def forward(self,\n",
    "                src: Tensor,\n",
    "                trg: Tensor,\n",
    "                src_mask: Tensor,\n",
    "                tgt_mask: Tensor,\n",
    "                src_padding_mask: Tensor,\n",
    "                tgt_padding_mask: Tensor,\n",
    "                memory_key_padding_mask: Tensor):\n",
    "        src_emb = self.positional_encoding(self.src_tok_emb(src))\n",
    "        tgt_emb = self.positional_encoding(self.tgt_tok_emb(trg))\n",
    "        outs = self.transformer(src_emb, tgt_emb, src_mask, tgt_mask, None,\n",
    "                                src_padding_mask, tgt_padding_mask, memory_key_padding_mask)\n",
    "        return self.generator(outs)\n",
    "\n",
    "    def encode(self, src: Tensor, src_mask: Tensor):\n",
    "        return self.transformer.encoder(self.positional_encoding(\n",
    "                            self.src_tok_emb(src)), src_mask)\n",
    "\n",
    "    def decode(self, tgt: Tensor, memory: Tensor, tgt_mask: Tensor):\n",
    "        return self.transformer.decoder(self.positional_encoding(\n",
    "                          self.tgt_tok_emb(tgt)), memory,\n",
    "                          tgt_mask)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "generating masks for sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_square_subsequent_mask(sz):\n",
    "    mask = (torch.triu(torch.ones((sz, sz), device=DEVICE)) == 1).transpose(0, 1)\n",
    "    mask = mask.float().masked_fill(mask == 0, float('-inf')).masked_fill(mask == 1, float(0.0))\n",
    "    return mask\n",
    "\n",
    "\n",
    "def create_mask(src, tgt):\n",
    "    src_seq_len = src.shape[0]\n",
    "    tgt_seq_len = tgt.shape[0]\n",
    "\n",
    "    tgt_mask = generate_square_subsequent_mask(tgt_seq_len)\n",
    "    src_mask = torch.zeros((src_seq_len, src_seq_len),device=DEVICE).type(torch.bool)\n",
    "\n",
    "    src_padding_mask = (src == PAD_IDX).transpose(0, 1)\n",
    "    tgt_padding_mask = (tgt == PAD_IDX).transpose(0, 1)\n",
    "    return src_mask, tgt_mask, src_padding_mask, tgt_padding_mask"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "setting up transformer instance on gpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\devbh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\transformer.py:306: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
      "c:\\Users\\devbh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(0)\n",
    "\n",
    "SRC_VOCAB_SIZE = len(vocab_transform[SRC_LANGUAGE])\n",
    "TGT_VOCAB_SIZE = len(vocab_transform[TGT_LANGUAGE])\n",
    "EMB_SIZE = 512\n",
    "NHEAD = 8\n",
    "FFN_HID_DIM = 512\n",
    "BATCH_SIZE = 128\n",
    "NUM_ENCODER_LAYERS = 6\n",
    "NUM_DECODER_LAYERS = 6\n",
    "\n",
    "transformer = Seq2SeqTransformer(NUM_ENCODER_LAYERS, NUM_DECODER_LAYERS, EMB_SIZE,\n",
    "                                 NHEAD, SRC_VOCAB_SIZE, TGT_VOCAB_SIZE, FFN_HID_DIM)\n",
    "\n",
    "for p in transformer.parameters():\n",
    "    if p.dim() > 1:\n",
    "        nn.init.xavier_uniform_(p)\n",
    "\n",
    "transformer = transformer.to(DEVICE)\n",
    "\n",
    "loss_fn = torch.nn.CrossEntropyLoss(ignore_index=PAD_IDX)\n",
    "\n",
    "optimizer = torch.optim.Adam(transformer.parameters(), lr=0.0001, betas=(0.9, 0.98), eps=1e-9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre - Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "pre-processing sequence data into tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn.utils.rnn import pad_sequence\n",
    "\n",
    "# helper function to club together sequential operations\n",
    "def sequential_transforms(*transforms):\n",
    "    def func(txt_input):\n",
    "        for transform in transforms:\n",
    "            txt_input = transform(txt_input)\n",
    "        return txt_input\n",
    "    return func\n",
    "\n",
    "# add begin of sentence and end of sentence tensors to each sequence\n",
    "def tensor_transform(token_ids: List[int]):\n",
    "    return torch.cat((torch.tensor([BOS_IDX]), torch.tensor(token_ids), torch.tensor([EOS_IDX])))\n",
    "\n",
    "# convert raw strings to tensor sequences with bos and eos tokens\n",
    "text_transform = {}\n",
    "for ln in [SRC_LANGUAGE, TGT_LANGUAGE]:\n",
    "    text_transform[ln] = sequential_transforms(token_transform[ln], vocab_transform[ln], tensor_transform) # Add BOS/EOS and create tensor\n",
    "\n",
    "\n",
    "# convert data samples into batch tensors\n",
    "def collate_fn(batch):\n",
    "    src_batch, tgt_batch = [], []\n",
    "    for src_sample, tgt_sample in batch:\n",
    "        src_batch.append(text_transform[SRC_LANGUAGE](src_sample.rstrip(\"\\n\")))\n",
    "        tgt_batch.append(text_transform[TGT_LANGUAGE](tgt_sample.rstrip(\"\\n\")))\n",
    "\n",
    "    src_batch = pad_sequence(src_batch, padding_value=PAD_IDX)\n",
    "    tgt_batch = pad_sequence(tgt_batch, padding_value=PAD_IDX)\n",
    "    return src_batch, tgt_batch\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# train and get training score\n",
    "def train_epoch(model, optimizer):\n",
    "    model.train()\n",
    "    losses = 0\n",
    "    train_iter = Multi30k(split='train', language_pair=(SRC_LANGUAGE, TGT_LANGUAGE))\n",
    "    train_dataloader = DataLoader(train_iter, batch_size=BATCH_SIZE, collate_fn=collate_fn)\n",
    "\n",
    "    for src, tgt in train_dataloader:\n",
    "        src = src.to(DEVICE)\n",
    "        tgt = tgt.to(DEVICE)\n",
    "\n",
    "        tgt_input = tgt[:-1, :]\n",
    "\n",
    "        src_mask, tgt_mask, src_padding_mask, tgt_padding_mask = create_mask(src, tgt_input)\n",
    "\n",
    "        logits = model(src, tgt_input, src_mask, tgt_mask,src_padding_mask, tgt_padding_mask, src_padding_mask)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        tgt_out = tgt[1:, :]\n",
    "        loss = loss_fn(logits.reshape(-1, logits.shape[-1]), tgt_out.reshape(-1))\n",
    "        loss.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "        losses += loss.item()\n",
    "\n",
    "    return losses / len(list(train_dataloader))\n",
    "\n",
    "\n",
    "# val test and get testing score\n",
    "def evaluate(model):\n",
    "    model.eval()\n",
    "    losses = 0\n",
    "    val_iter = Multi30k(split='valid', language_pair=(SRC_LANGUAGE, TGT_LANGUAGE))\n",
    "    val_dataloader = DataLoader(val_iter, batch_size=BATCH_SIZE, collate_fn=collate_fn)\n",
    "\n",
    "    for src, tgt in val_dataloader:\n",
    "        src = src.to(DEVICE)\n",
    "        tgt = tgt.to(DEVICE)\n",
    "\n",
    "        tgt_input = tgt[:-1, :]\n",
    "\n",
    "        src_mask, tgt_mask, src_padding_mask, tgt_padding_mask = create_mask(src, tgt_input)\n",
    "\n",
    "        logits = model(src, tgt_input, src_mask, tgt_mask,src_padding_mask, tgt_padding_mask, src_padding_mask)\n",
    "\n",
    "        tgt_out = tgt[1:, :]\n",
    "        loss = loss_fn(logits.reshape(-1, logits.shape[-1]), tgt_out.reshape(-1))\n",
    "        losses += loss.item()\n",
    "\n",
    "    return losses / len(list(val_dataloader))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation / Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# old results\n",
    "\n",
    "# Epoch: 1, Train loss: 6.030, Val loss: 4.919, Epoch time = 33.900s\n",
    "# Epoch: 2, Train loss: 4.426, Val loss: 4.191, Epoch time = 34.678s\n",
    "# Epoch: 3, Train loss: 3.859, Val loss: 3.821, Epoch time = 34.680s\n",
    "# Epoch: 4, Train loss: 3.505, Val loss: 3.562, Epoch time = 34.593s\n",
    "# Epoch: 5, Train loss: 3.231, Val loss: 3.348, Epoch time = 34.684s\n",
    "# Epoch: 6, Train loss: 2.973, Val loss: 3.155, Epoch time = 34.728s\n",
    "# Epoch: 7, Train loss: 2.755, Val loss: 3.012, Epoch time = 34.772s\n",
    "# Epoch: 8, Train loss: 2.556, Val loss: 2.858, Epoch time = 35.046s\n",
    "# Epoch: 9, Train loss: 2.375, Val loss: 2.728, Epoch time = 34.899s\n",
    "# Epoch: 10, Train loss: 2.210, Val loss: 2.626, Epoch time = 34.875s\n",
    "# Epoch: 11, Train loss: 2.052, Val loss: 2.518, Epoch time = 34.766s\n",
    "# Epoch: 12, Train loss: 1.912, Val loss: 2.423, Epoch time = 34.636s\n",
    "# Epoch: 13, Train loss: 1.789, Val loss: 2.356, Epoch time = 35.038s\n",
    "# Epoch: 14, Train loss: 1.690, Val loss: 2.290, Epoch time = 35.041s\n",
    "# Epoch: 15, Train loss: 1.591, Val loss: 2.236, Epoch time = 34.995s\n",
    "# Epoch: 16, Train loss: 1.497, Val loss: 2.204, Epoch time = 35.062s\n",
    "# Epoch: 17, Train loss: 1.419, Val loss: 2.198, Epoch time = 35.154s\n",
    "# Epoch: 18, Train loss: 1.342, Val loss: 2.211, Epoch time = 34.992s\n",
    "# Epoch: 19, Train loss: 1.276, Val loss: 2.191, Epoch time = 34.876s\n",
    "# Epoch: 20, Train loss: 1.212, Val loss: 2.156, Epoch time = 35.040s\n",
    "# Epoch: 21, Train loss: 1.149, Val loss: 2.098, Epoch time = 34.895s\n",
    "# Epoch: 22, Train loss: 1.090, Val loss: 2.088, Epoch time = 34.889s\n",
    "# Epoch: 23, Train loss: 1.036, Val loss: 2.077, Epoch time = 35.073s\n",
    "# Epoch: 24, Train loss: 0.985, Val loss: 2.069, Epoch time = 35.024s\n",
    "# Epoch: 25, Train loss: 0.939, Val loss: 2.076, Epoch time = 34.987s\n",
    "# Epoch: 26, Train loss: 0.899, Val loss: 2.083, Epoch time = 35.114s\n",
    "# Epoch: 27, Train loss: 0.852, Val loss: 2.093, Epoch time = 34.957s\n",
    "# Epoch: 28, Train loss: 0.813, Val loss: 2.088, Epoch time = 35.105s\n",
    "# Epoch: 29, Train loss: 0.775, Val loss: 2.108, Epoch time = 34.948s\n",
    "# Epoch: 30, Train loss: 0.738, Val loss: 2.094, Epoch time = 34.970s\n",
    "# Epoch: 31, Train loss: 0.698, Val loss: 2.097, Epoch time = 34.902s\n",
    "# Epoch: 32, Train loss: 0.661, Val loss: 2.107, Epoch time = 34.790s\n",
    "# Epoch: 33, Train loss: 0.630, Val loss: 2.136, Epoch time = 34.962s\n",
    "# Epoch: 34, Train loss: 0.598, Val loss: 2.152, Epoch time = 35.065s\n",
    "# Epoch: 35, Train loss: 0.567, Val loss: 2.186, Epoch time = 35.007s\n",
    "# Epoch: 36, Train loss: 0.540, Val loss: 2.199, Epoch time = 35.307s\n",
    "# Epoch: 37, Train loss: 0.517, Val loss: 2.235, Epoch time = 35.087s\n",
    "# Epoch: 38, Train loss: 0.491, Val loss: 2.246, Epoch time = 34.943s\n",
    "# Epoch: 39, Train loss: 0.462, Val loss: 2.245, Epoch time = 35.096s\n",
    "# Epoch: 40, Train loss: 0.440, Val loss: 2.278, Epoch time = 34.942s\n",
    "# Epoch: 41, Train loss: 0.416, Val loss: 2.344, Epoch time = 34.911s\n",
    "# Epoch: 42, Train loss: 0.396, Val loss: 2.326, Epoch time = 34.910s\n",
    "# Epoch: 43, Train loss: 0.373, Val loss: 2.355, Epoch time = 35.258s\n",
    "# Epoch: 44, Train loss: 0.354, Val loss: 2.377, Epoch time = 34.861s\n",
    "# Epoch: 45, Train loss: 0.336, Val loss: 2.393, Epoch time = 35.147s\n",
    "# Epoch: 46, Train loss: 0.319, Val loss: 2.417, Epoch time = 35.039s\n",
    "# Epoch: 47, Train loss: 0.299, Val loss: 2.466, Epoch time = 34.958s\n",
    "# Epoch: 48, Train loss: 0.282, Val loss: 2.494, Epoch time = 34.989s\n",
    "# Epoch: 49, Train loss: 0.268, Val loss: 2.490, Epoch time = 35.231s\n",
    "# Epoch: 50, Train loss: 0.257, Val loss: 2.531, Epoch time = 34.896s\n",
    "# Epoch: 51, Train loss: 0.246, Val loss: 2.537, Epoch time = 34.821s\n",
    "# Epoch: 52, Train loss: 0.234, Val loss: 2.574, Epoch time = 34.825s\n",
    "# Epoch: 53, Train loss: 0.224, Val loss: 2.615, Epoch time = 35.018s\n",
    "# Epoch: 54, Train loss: 0.214, Val loss: 2.611, Epoch time = 35.077s\n",
    "# Epoch: 55, Train loss: 0.205, Val loss: 2.628, Epoch time = 34.940s\n",
    "# Epoch: 56, Train loss: 0.196, Val loss: 2.623, Epoch time = 35.033s\n",
    "# Epoch: 57, Train loss: 0.187, Val loss: 2.634, Epoch time = 35.096s\n",
    "# Epoch: 58, Train loss: 0.177, Val loss: 2.653, Epoch time = 35.158s\n",
    "# Epoch: 59, Train loss: 0.170, Val loss: 2.636, Epoch time = 35.053s\n",
    "# Epoch: 60, Train loss: 0.161, Val loss: 2.688, Epoch time = 34.996s\n",
    "# Epoch: 61, Train loss: 0.157, Val loss: 2.691, Epoch time = 34.922s\n",
    "# Epoch: 62, Train loss: 0.150, Val loss: 2.699, Epoch time = 34.927s\n",
    "# Epoch: 63, Train loss: 0.143, Val loss: 2.711, Epoch time = 34.950s\n",
    "# Epoch: 64, Train loss: 0.139, Val loss: 2.747, Epoch time = 34.863s\n",
    "# Epoch: 65, Train loss: 0.133, Val loss: 2.773, Epoch time = 34.875s\n",
    "# Epoch: 66, Train loss: 0.129, Val loss: 2.777, Epoch time = 35.394s\n",
    "# Epoch: 67, Train loss: 0.124, Val loss: 2.786, Epoch time = 35.013s\n",
    "# Epoch: 68, Train loss: 0.118, Val loss: 2.799, Epoch time = 34.953s\n",
    "# Epoch: 69, Train loss: 0.114, Val loss: 2.795, Epoch time = 35.025s\n",
    "# Epoch: 70, Train loss: 0.109, Val loss: 2.805, Epoch time = 34.948s\n",
    "# Epoch: 71, Train loss: 0.107, Val loss: 2.823, Epoch time = 35.057s\n",
    "# Epoch: 72, Train loss: 0.101, Val loss: 2.845, Epoch time = 34.997s\n",
    "# Epoch: 73, Train loss: 0.099, Val loss: 2.821, Epoch time = 35.064s\n",
    "# Epoch: 74, Train loss: 0.095, Val loss: 2.855, Epoch time = 35.137s\n",
    "# Epoch: 75, Train loss: 0.092, Val loss: 2.893, Epoch time = 35.190s\n",
    "# Epoch: 76, Train loss: 0.091, Val loss: 2.865, Epoch time = 35.150s\n",
    "# Epoch: 77, Train loss: 0.086, Val loss: 2.891, Epoch time = 35.208s\n",
    "# Epoch: 78, Train loss: 0.083, Val loss: 2.893, Epoch time = 35.236s\n",
    "# Epoch: 79, Train loss: 0.081, Val loss: 2.896, Epoch time = 35.159s\n",
    "# Epoch: 80, Train loss: 0.080, Val loss: 2.912, Epoch time = 35.170s\n",
    "# Epoch: 81, Train loss: 0.076, Val loss: 2.903, Epoch time = 35.340s\n",
    "# Epoch: 82, Train loss: 0.074, Val loss: 2.953, Epoch time = 35.177s\n",
    "# Epoch: 83, Train loss: 0.072, Val loss: 2.946, Epoch time = 35.285s\n",
    "# Epoch: 84, Train loss: 0.070, Val loss: 2.953, Epoch time = 35.356s\n",
    "# Epoch: 85, Train loss: 0.068, Val loss: 2.934, Epoch time = 35.594s\n",
    "# Epoch: 86, Train loss: 0.066, Val loss: 2.958, Epoch time = 34.910s\n",
    "# Epoch: 87, Train loss: 0.066, Val loss: 2.994, Epoch time = 35.257s\n",
    "# Epoch: 88, Train loss: 0.063, Val loss: 2.993, Epoch time = 35.809s\n",
    "# Epoch: 89, Train loss: 0.062, Val loss: 2.999, Epoch time = 35.024s\n",
    "# Epoch: 90, Train loss: 0.059, Val loss: 3.001, Epoch time = 35.044s\n",
    "# Epoch: 91, Train loss: 0.058, Val loss: 3.053, Epoch time = 35.422s\n",
    "# Epoch: 92, Train loss: 0.057, Val loss: 3.072, Epoch time = 36.464s\n",
    "# Epoch: 93, Train loss: 0.055, Val loss: 3.073, Epoch time = 36.489s\n",
    "# Epoch: 94, Train loss: 0.055, Val loss: 3.053, Epoch time = 36.655s\n",
    "# Epoch: 95, Train loss: 0.053, Val loss: 3.060, Epoch time = 36.113s\n",
    "# Epoch: 96, Train loss: 0.050, Val loss: 3.077, Epoch time = 35.800s\n",
    "# Epoch: 97, Train loss: 0.050, Val loss: 3.097, Epoch time = 36.179s\n",
    "# Epoch: 98, Train loss: 0.048, Val loss: 3.114, Epoch time = 36.577s\n",
    "# Epoch: 99, Train loss: 0.047, Val loss: 3.114, Epoch time = 36.240s\n",
    "# Epoch: 100, Train loss: 0.047, Val loss: 3.103, Epoch time = 37.015s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\devbh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\functional.py:5504: UserWarning: 1Torch was not compiled with flash attention. (Triggered internally at ..\\aten\\src\\ATen\\native\\transformers\\cuda\\sdp_utils.cpp:455.)\n",
      "  attn_output = scaled_dot_product_attention(q, k, v, attn_mask, dropout_p, is_causal)\n",
      "c:\\Users\\devbh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\functional.py:5137: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.\n",
      "  warnings.warn(\n",
      "c:\\Users\\devbh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\utils\\data\\datapipes\\iter\\combining.py:337: UserWarning: Some child DataPipes are not exhausted when __iter__ is called. We are resetting the buffer and each child DataPipe will read from the start again.\n",
      "  warnings.warn(\"Some child DataPipes are not exhausted when __iter__ is called. We are resetting \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, Train loss: 6.030, Val loss: 4.919, Epoch time = 32.250s\n",
      "Epoch: 2, Train loss: 4.426, Val loss: 4.191, Epoch time = 34.463s\n",
      "Epoch: 3, Train loss: 3.859, Val loss: 3.821, Epoch time = 35.960s\n",
      "Epoch: 4, Train loss: 3.505, Val loss: 3.562, Epoch time = 35.788s\n",
      "Epoch: 5, Train loss: 3.231, Val loss: 3.348, Epoch time = 35.772s\n",
      "Epoch: 6, Train loss: 2.973, Val loss: 3.155, Epoch time = 35.687s\n",
      "Epoch: 7, Train loss: 2.755, Val loss: 3.012, Epoch time = 35.039s\n",
      "Epoch: 8, Train loss: 2.556, Val loss: 2.858, Epoch time = 35.086s\n",
      "Epoch: 9, Train loss: 2.375, Val loss: 2.728, Epoch time = 34.966s\n",
      "Epoch: 10, Train loss: 2.210, Val loss: 2.626, Epoch time = 34.958s\n",
      "Epoch: 11, Train loss: 2.052, Val loss: 2.518, Epoch time = 34.817s\n",
      "Epoch: 12, Train loss: 1.912, Val loss: 2.423, Epoch time = 35.085s\n",
      "Epoch: 13, Train loss: 1.789, Val loss: 2.356, Epoch time = 35.362s\n",
      "Epoch: 14, Train loss: 1.690, Val loss: 2.290, Epoch time = 35.218s\n",
      "Epoch: 15, Train loss: 1.591, Val loss: 2.236, Epoch time = 34.237s\n",
      "Epoch: 16, Train loss: 1.497, Val loss: 2.204, Epoch time = 34.867s\n",
      "Epoch: 17, Train loss: 1.419, Val loss: 2.198, Epoch time = 34.916s\n",
      "Epoch: 18, Train loss: 1.342, Val loss: 2.211, Epoch time = 34.886s\n",
      "Epoch: 19, Train loss: 1.276, Val loss: 2.191, Epoch time = 35.015s\n",
      "Epoch: 20, Train loss: 1.212, Val loss: 2.156, Epoch time = 37.566s\n",
      "Epoch: 21, Train loss: 1.149, Val loss: 2.098, Epoch time = 37.670s\n",
      "Epoch: 22, Train loss: 1.090, Val loss: 2.088, Epoch time = 38.377s\n",
      "Epoch: 23, Train loss: 1.036, Val loss: 2.077, Epoch time = 36.851s\n",
      "Epoch: 24, Train loss: 0.985, Val loss: 2.069, Epoch time = 37.464s\n"
     ]
    }
   ],
   "source": [
    "from timeit import default_timer as timer\n",
    "NUM_EPOCHS = 24\n",
    "\n",
    "for epoch in range(1, NUM_EPOCHS + 1):\n",
    "    start_time = timer()\n",
    "    train_loss = train_epoch(transformer, optimizer)\n",
    "    end_time = timer()\n",
    "    val_loss = evaluate(transformer)\n",
    "    print((f\"Epoch: {epoch}, Train loss: {train_loss:.3f}, Val loss: {val_loss:.3f}, \"f\"Epoch time = {(end_time - start_time):.3f}s\"))\n",
    "\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "\n",
    "# function to generate output sequence using greedy algorithm\n",
    "def greedy_decode(model, src, src_mask, max_len, start_symbol):\n",
    "    src = src.to(DEVICE)\n",
    "    src_mask = src_mask.to(DEVICE)\n",
    "\n",
    "    memory = model.encode(src, src_mask)\n",
    "    ys = torch.ones(1, 1).fill_(start_symbol).type(torch.long).to(DEVICE)\n",
    "    for i in range(max_len-1):\n",
    "        memory = memory.to(DEVICE)\n",
    "        tgt_mask = (generate_square_subsequent_mask(ys.size(0))\n",
    "                    .type(torch.bool)).to(DEVICE)\n",
    "        out = model.decode(ys, memory, tgt_mask)\n",
    "        out = out.transpose(0, 1)\n",
    "        prob = model.generator(out[:, -1])\n",
    "        _, next_word = torch.max(prob, dim=1)\n",
    "        next_word = next_word.item()\n",
    "\n",
    "        ys = torch.cat([ys,\n",
    "                        torch.ones(1, 1).type_as(src.data).fill_(next_word)], dim=0)\n",
    "        if next_word == EOS_IDX:\n",
    "            break\n",
    "    return ys\n",
    "\n",
    "\n",
    "# actual function to translate input sentence into target language\n",
    "def translate(model: torch.nn.Module, src_sentence: str):\n",
    "    model.eval()\n",
    "    src = text_transform[SRC_LANGUAGE](src_sentence).view(-1, 1).to(DEVICE)  # Move src tensor to device\n",
    "    num_tokens = src.shape[0]\n",
    "    src_mask = (torch.zeros(num_tokens, num_tokens)).type(torch.bool).to(DEVICE)  # Move src_mask tensor to device\n",
    "    tgt_tokens = greedy_decode(\n",
    "        model,  src, src_mask, max_len=num_tokens + 5, start_symbol=BOS_IDX).flatten()\n",
    "    return \" \".join(vocab_transform[TGT_LANGUAGE].lookup_tokens(list(tgt_tokens.cpu().numpy()))).replace(\"<bos>\", \"\").replace(\"<eos>\", \"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MODEL_SAVE_PATH = \"transformer_model.pth\"\n",
    "\n",
    "# torch.cuda.empty_cache()\n",
    "\n",
    "# torch.save(transformer.state_dict(), MODEL_SAVE_PATH)\n",
    "# print(\"Model saved!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Ein Mann in einer Lederjacke schaut aus einem Gebäude , während vor ihm von einem Zaun zusieht . \n"
     ]
    }
   ],
   "source": [
    "print(translate(transformer, \"Outside a building, a uniformed security guard looks at the camera from behind a fence.\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "the german.txt file is the google translated content of test.en"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences_en = []\n",
    "sentences_de = []\n",
    "predicted_de = []\n",
    "\n",
    "with open(\"./test/english.txt\", \"r\", encoding=\"utf-8\") as f:\n",
    "    sentences_en = f.readlines()\n",
    "\n",
    "with open(\"./test/german.txt\", \"r\", encoding=\"utf-8\") as f:\n",
    "    sentences_de = f.readlines()\n",
    "\n",
    "for sample in sentences_en:\n",
    "    predicted_de.append(translate(transformer, sample))\n",
    "\n",
    "with open(\"./test/pred_24.txt\", \"wb\") as f:\n",
    "    f.writelines([x.encode('utf-8') for x in '\\n'.join(predicted_de)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU Score: 0.2506802796280982\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torchtext.data.utils import get_tokenizer\n",
    "from nltk.translate.bleu_score import corpus_bleu\n",
    "from torchtext.data.utils import get_tokenizer\n",
    "\n",
    "# Load tokenizer\n",
    "tokenizer = get_tokenizer('spacy', language='en_core_web_sm')\n",
    "\n",
    "# Load sentences from files\n",
    "def load_sentences(file_path):\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        lines = file.readlines()\n",
    "    return [line.strip() for line in lines]\n",
    "\n",
    "# Define file paths\n",
    "reference_file = \"./test/german.txt\"\n",
    "candidate_file = \"./test/pred.txt\"\n",
    "\n",
    "# Load sentences\n",
    "reference_sentences = load_sentences(reference_file)\n",
    "candidate_sentences = load_sentences(candidate_file)\n",
    "\n",
    "# Tokenize sentences\n",
    "reference_tokenized = [tokenizer(sentence) for sentence in reference_sentences]\n",
    "candidate_tokenized = [tokenizer(sentence) for sentence in candidate_sentences]\n",
    "\n",
    "# Calculate BLEU score\n",
    "bleu_score = corpus_bleu([[ref] for ref in reference_tokenized], candidate_tokenized)\n",
    "print(\"BLEU Score:\", bleu_score)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
